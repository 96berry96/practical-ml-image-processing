{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make Sure that both the images are in the same folder\n",
      "Displaying SIFT Features\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Sift_Operations import *\n",
    "\n",
    "print('''Make Sure that both the images are in the same folder''')\n",
    "\n",
    "x = input(\"Enter First Image Name: \")\n",
    "Image1 = cv2.imread(x)\n",
    "y = input(\"Enter Second Image Name: \")\n",
    "Image2 = cv2.imread(y)\n",
    "\n",
    "Image1_gray = cv2.cvtColor(Image1, cv2.COLOR_BGR2GRAY)\n",
    "Image2_gray = cv2.cvtColor(Image2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "Image1_key_points, Image1_descriptors = extract_sift_features(Image1_gray)\n",
    "Image2_key_points, Image2_descriptors = extract_sift_features(Image2_gray)\n",
    "\n",
    "print( 'Displaying SIFT Features')\n",
    "showing_sift_features(Image1_gray, Image1, Image1_key_points);\n",
    "\n",
    "norm = cv2.NORM_L2\n",
    "bruteForce = cv2.BFMatcher(norm)\n",
    "\n",
    "matches = bruteForce.match(Image1_descriptors, Image2_descriptors)\n",
    "\n",
    "matches = sorted(matches, key = lambda match:match.distance)\n",
    "\n",
    "matched_img = cv2.drawMatches(\n",
    "    Image1, Image1_key_points,\n",
    "    Image2, Image2_key_points,\n",
    "    matches[:100], Image2.copy())\n",
    "\n",
    "#plt.figure(figsize=(100,300))\n",
    "cv2.imwrite(\"kp.jpg\",matched_img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1b3ff8b82d50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"shelf.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"1.jpg\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRANSAC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "from skimage import feature, color, transform, io\n",
    "import numpy as np\n",
    "import logging\n",
    "import cv2\n",
    "from Ransac_Operations import *\n",
    "\n",
    "image = cv2.imread(\"shelf.jpg\")\n",
    "io.imsave(\"1.jpg\", rectify_image(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Registration"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sohails\\Himanshu\\Image Processing\\Affine.py:24: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  theta = np.linalg.lstsq(M, b)[0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from Ransac import *\n",
    "from Affine import *\n",
    "from Align import *\n",
    "\n",
    "img_source = cv2.imread(\"2.jpg\")\n",
    "img_target = cv2.imread(\"target.jpg\")\n",
    "keypoint_source, descriptor_source = extract_SIFT(img_source)\n",
    "keypoint_target, descriptor_target = extract_SIFT(img_target)\n",
    "pos = match_SIFT(descriptor_source, descriptor_target)\n",
    "H = affine_matrix(keypoint_source, keypoint_target, pos)\n",
    "\n",
    "rows, cols, _ = img_target.shape\n",
    "warp = cv2.warpAffine(img_source, H, (cols, rows))\n",
    "merge = np.uint8(img_target * 0.5 + warp * 0.5)\n",
    "cv2.imshow('img', merge)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2239)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoint_target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stitching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sohails\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.2589 - acc: 0.9206 - val_loss: 0.0558 - val_acc: 0.9820\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0868 - acc: 0.9748 - val_loss: 0.0425 - val_acc: 0.9853\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0664 - acc: 0.9804 - val_loss: 0.0327 - val_acc: 0.9883\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0537 - acc: 0.9839 - val_loss: 0.0311 - val_acc: 0.9889\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 197s 3ms/step - loss: 0.0459 - acc: 0.9862 - val_loss: 0.0310 - val_acc: 0.9893\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0407 - acc: 0.9875 - val_loss: 0.0304 - val_acc: 0.9897\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0364 - acc: 0.9895 - val_loss: 0.0294 - val_acc: 0.9901\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.0340 - acc: 0.9898 - val_loss: 0.0290 - val_acc: 0.9907\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.0311 - acc: 0.9907 - val_loss: 0.0265 - val_acc: 0.9917\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.0285 - acc: 0.9915 - val_loss: 0.0252 - val_acc: 0.9920\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0275 - acc: 0.9914 - val_loss: 0.0264 - val_acc: 0.9920\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0264 - acc: 0.9921 - val_loss: 0.0264 - val_acc: 0.9918\n",
      "Test loss: 0.026368951098990512\n",
      "Test accuracy: 0.9918\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from Load_and_Preprocess import *\n",
    "\n",
    "x_train,x_test,y_train,y_test, input_shape = load_and_preprocess()\n",
    "num_classes=10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=12,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST - ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "42000/42000 [==============================] - 55s 1ms/step - loss: 0.0207 - acc: 0.8769\n",
      "Epoch 2/10\n",
      "42000/42000 [==============================] - 58s 1ms/step - loss: 0.0091 - acc: 0.9505\n",
      "Epoch 3/10\n",
      "42000/42000 [==============================] - 57s 1ms/step - loss: 0.0067 - acc: 0.9643\n",
      "Epoch 4/10\n",
      "42000/42000 [==============================] - 51s 1ms/step - loss: 0.0053 - acc: 0.9713\n",
      "Epoch 5/10\n",
      "42000/42000 [==============================] - 52s 1ms/step - loss: 0.0043 - acc: 0.9771\n",
      "Epoch 6/10\n",
      "42000/42000 [==============================] - 59s 1ms/step - loss: 0.0036 - acc: 0.9806\n",
      "Epoch 7/10\n",
      "42000/42000 [==============================] - 59s 1ms/step - loss: 0.0031 - acc: 0.9837\n",
      "Epoch 8/10\n",
      "42000/42000 [==============================] - 59s 1ms/step - loss: 0.0026 - acc: 0.9857\n",
      "Epoch 9/10\n",
      "42000/42000 [==============================] - 59s 1ms/step - loss: 0.0023 - acc: 0.9876\n",
      "Epoch 10/10\n",
      "42000/42000 [==============================] - 60s 1ms/step - loss: 0.0020 - acc: 0.9895\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "input_data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "y = input_data['label']\n",
    "input_data.drop('label',axis=1,inplace = True)\n",
    "X = input_data\n",
    "y = pd.get_dummies(y)\n",
    "\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(units = 600, kernel_initializer = 'uniform', activation = 'relu', input_dim = 784))\n",
    "classifier.add(Dense(units = 400, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(units = 200, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "classifier.add(Dense(units = 10, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "classifier.compile(optimizer = 'sgd', loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "\n",
    "classifier.fit(X, y, batch_size = 10, epochs = 10)\n",
    "\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "y_pred = classifier.predict(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['label']\n",
    "data.drop('label',axis=1,inplace = True)\n",
    "X = data\n",
    "y = pd.Categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "dt = DecisionTreeClassifier()\n",
    "svc = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logreg = logreg.fit(X,y)\n",
    "model_dt = dt.fit(X,y)\n",
    "model_svc = svc.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"test.csv\")\n",
    "pred_logreg = model_logreg.predict(X_test)\n",
    "pred_dt = model_logreg.predict(X_test)\n",
    "pred_svc = model_logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_logreg = model_logreg.predict(X)\n",
    "pred_dt = model_dt.predict(X)\n",
    "pred_svc = model_svc.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy is:  100.0\n",
      "Logistic Regression Accuracy is:  93.8547619047619\n",
      "Support Vector Machine Accuracy is:  88.26190476190476\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Decision Tree Accuracy is: \", accuracy_score(pred_dt, y)*100)\n",
    "print(\"Logistic Regression Accuracy is: \", accuracy_score(pred_logreg, y)*100)\n",
    "print(\"Support Vector Machine Accuracy is: \", accuracy_score(pred_svc, y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
